# HuaWeiCodeCraft2018
华为软件精英挑战赛2018

***

# 机器学习

### 章节目录

* 1.引言；棋盘问题建模
* 2.概念学习和一般到特殊序
* 3.决策树学习
* 4.人工神经网络
* 5.评估假设
* 6.贝叶斯学习
* 7.计算学习理论
* 8.基于实例的学习
* 9.遗传算法
* 10.学习规则集合
* 11.分析学习
* 12.归纳和分析学习的结合
* 13.增强学习

### 训练经验

类型：
* 直接(各种棋盘状态，相应正确走子)
* 间接(走子序列&最终结局)，涉及每一步的信用分配问题

学习器如何控制训练样例序列
* 与施教者即训练样本的关系

训练样本能多好地表示实例分布
* 很多的机器学习理论都是基于训练样例与测试样例分布一致这一假设

### 西洋跳棋学习问题

* 任务T；性能标准P；训练经验E
* 需要选择: 学习的知识的类型；对于目标知识的表示；一种学习机制
* 从一个大的合法走子空间中选择最佳走子
* 学习function：ChooseMove；问题简化为学习像ChooseMove这样某个特定的目标函数(TargetFunction)；所以TargetFunction的选择很重要
* 另外一个可供选择的目标函数是一个评估函数，它为任何给定棋局赋予一个数字评分
V：B->R表示V把任何合法的棋局从集合B映射到某个实数值
* 定义如下：b最终胜局，V(b)=100;
b最终负，V(b)=-100;
b最终和局,V(b)=0;
b不是最终棋局，V(b)=b(b').
然而这个定义对于某一种中间状态需要决定其后的所有路线，因此是不可操作的定义
* 任务被简化为一个理想目标函数V的可操作描述，学习这个目标函数的过程常被称为函数逼近

简单选择一个线性目标函数
* 六个参数，黑子，红子，黑王，红王，被威胁黑子数量，被威胁红子数量
* 跳棋程序的部分设计为：
T:下西洋跳棋；P:世界锦标赛上击败对手的百分比；
E:和自己对弈;V：Board->R；目标函数表示：线性加权
* 需要一系列训练样例，每一个训练样例描述了特定的棋盘状态b和训练值v(b)
* 学习器可以得到的训练信息仅是对弈最后的胜负；同时，我们需要训练样例为每个棋盘状态赋予一个分值。
难点在于给每个棋盘的中间状态赋予一个分值。
* 一个简单的方法取得了良好的效果：用后继棋局的近似值来估计训练值；事实上，这种基于对后继棋局进行估计的迭代估计训练值的方法，已被证明可以近乎完美地收敛到估计值。
* 定义最佳拟合的含义：使训练值和假设V预测出的值间的误差平方和E最小
* 已经知道一些算法可以得到线性函数的权使此定义的E最小化，这里需要一个算法使得它可以再有了新的训练样例时进一步精化权值，并且它对估计的训练数据中的差错有好的健壮性，LMS训练方法。least mean squares
* 这个算法可被看作对可能的假设空间进行随机的梯度下降搜索。。。
* 学习程序的最终设计
实验生成器；执行系统(输入新问题，输出解答路线)；鉴定器(历史记录作为输入，输出训练样例目标函数Vtrain;估计法则)；泛化器(输入训练样例Vtrain，输出权值w)

### 第二章

* 概念学习任务：已知实例集X；假设集H；目标概念c；训练样集D；求解：H中的一般假设h，使得X中任意x，h(x)=c(x)
* 通常可以用序偶来描述训练样例；归纳学习假设，假定对于未见实例最好的假设就是与训练数据最佳拟合的假设，这是归纳学习的一个基本假定。
* 归纳学习假设：任一假设如果在足够大的训练样集中很好地逼近目标函数，它也能在未见实例中很好地逼近目标函数。
* 引起我们兴趣的算法应能有效地搜索非常大的或无限大的假设空间，以找到最佳拟合训练数据的假设。
* 一般到特殊的关系，即集合的包含与被包含关系；偏序关系，两个集合间不存在包含与被包含关系但有重合。偏序关系对任意概念学习提供了一种有效的结构
* FIND-S:寻找极大特殊假设；
1. 将h初始化为H中最特殊假设
2. 对每个正例x；h中的每个属性约束a，若x满足a则不做任何处理，否则将h中a替换为x满足的另一个更一般约束；
3. 输出假设h